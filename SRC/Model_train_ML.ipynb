{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modules import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5GG2ee5dh2qb"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import os\n",
        "import modelHandler\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import KMeansSMOTE, SMOTE, SVMSMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "NDHh0RcNjuIh"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../Data/train.csv', index_col = 0)\n",
        "df_test = pd.read_csv('../Data/test_x.csv', index_col = 0)\n",
        "\n",
        "\n",
        "cols_train = ['Hour', 'Sensor_beta', 'Sensor_gamma',\n",
        "       'Sensor_alpha_plus']\n",
        "target_train = ['Insect']\n",
        "\n",
        "x_train = df_train[cols_train].to_numpy()\n",
        "y_train = df_train[target_train].to_numpy().ravel()\n",
        "\n",
        "x_test = df_test[cols_train].to_numpy() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL2tZMjwrC4S",
        "outputId": "996936cc-6e18-4e89-e91b-b1c8aba9e455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 3519, 1: 2793, 2: 689}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq7V9A9Fql_2",
        "outputId": "85f215b0-43ca-426d-9d03-d2bb6a93f91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7001, 4)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the EDA and several model tests such as knn, svm and dt, I have seen that the best performing model is the XGBClassifier and it is the one I will focus on this notebook (the one I will hand)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6ENlLC9VDn7"
      },
      "source": [
        "### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UulN-NnGul0Y"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.2, random_state=42) #Training and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SMOTE to balance data proportions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bJP7z7YvAo0",
        "outputId": "108496a4-4020-4921-b138-092621558786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 2823, 1: 2823, 2: 2823}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm = SMOTE(random_state = 42, n_jobs = -1)\n",
        "x0, y0 = sm.fit_resample(X_train0, y_train0)\n",
        "unique, counts = np.unique(y0, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc9Dvzs9jqkx"
      },
      "outputs": [],
      "source": [
        "x = modelHandler.ModelHandler(X = x0, Y = y0, model = 'XGB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-LxYac1mfsa",
        "outputId": "e42fba9e-598c-4b97-c814-3e0d0901b039"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1200 fits failed out of a total of 7200.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1200 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n",
            "    xgb_model=xgb_model, callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n",
            "    dtrain.handle))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: value 2 for Parameter colsample_bytree exceed bound [0,1]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.90141677 0.90011806 0.89704841 ... 0.65478158 0.65478158 0.65478158]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] The best parameters are {'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6}\n",
            "[INFO] The best score is 0.9367\n",
            "[INFO] The best parameters according to ci are {'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6}\n",
            "[INFO] Train acc  is : 0.9976\n"
          ]
        }
      ],
      "source": [
        "x.fit() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGk0Bhfoac4V",
        "outputId": "1a92ac3f-9964-49c4-9ea3-2bc61c2eac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBClassifier(colsample_bytree=1.0, gamma=0.5, max_depth=32,\n",
            "              min_child_weight=0.5, objective='multi:softprob', subsample=0.6)\n"
          ]
        }
      ],
      "source": [
        "print(x.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best parameters are saved for further study after grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjiEQ8TGmhQs"
      },
      "outputs": [],
      "source": [
        "x.save('xgb_Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHPSvl7uPi_B"
      },
      "outputs": [],
      "source": [
        "##{'colsample_bytree': 1.0, 'gamma': 0, 'max_depth': 16, 'min_child_weight': 1, 'n_estimators': 80, 'subsample': 0.8}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUeaPdJoVPIE"
      },
      "source": [
        "## Subsampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v-JLPXYoVQyC"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C1CrJ_LVjuB",
        "outputId": "adde4b4c-96a9-4122-8564-61a4f8f290cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgraciae/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:11:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2824\n",
            "           1       1.00      1.00      1.00      2234\n",
            "           2       1.00      1.00      1.00       542\n",
            "\n",
            "    accuracy                           1.00      5600\n",
            "   macro avg       1.00      1.00      1.00      5600\n",
            "weighted avg       1.00      1.00      1.00      5600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mod = XGBClassifier(**{'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6})\n",
        "mod.fit(X_train0, y_train0)\n",
        "xgb2 = sklearn.metrics.classification_report(mod.predict(X_train0), y_train0)\n",
        "print(xgb2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQgHa2CXVrgV",
        "outputId": "1c87d4c8-dc70-4392-de10-ceb6c07c613f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92       723\n",
            "           1       0.95      0.93      0.94       571\n",
            "           2       0.62      0.85      0.72       107\n",
            "\n",
            "    accuracy                           0.91      1401\n",
            "   macro avg       0.84      0.89      0.86      1401\n",
            "weighted avg       0.92      0.91      0.91      1401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb3 = sklearn.metrics.classification_report(mod.predict(X_test0), y_test0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIenvCz0aRwb"
      },
      "source": [
        "### Equaling all data proportion (cutting data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1zNs5dUhaUm8"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2-kKvCAaZLK",
        "outputId": "5556263e-1f60-4eed-88b5-6dbef485401e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 2475, 1: 1936, 2: 489}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique, counts = np.unique(y_train0, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aB1lk0LybNiU"
      },
      "outputs": [],
      "source": [
        "tu = np.zeros((500*2 + 489,4))\n",
        "tu[:500] = X_train0[y_train0 == 1][:500]\n",
        "tu[500:1000] = X_train0[y_train0 == 0][:500]\n",
        "tu[1000:] = X_train0[y_train0 == 2]\n",
        "tuy = np.zeros((500*2 + 489))\n",
        "tuy[:500] = y_train0[y_train0 == 1][:500]\n",
        "tuy[500:1000] = y_train0[y_train0 == 0][:500]\n",
        "tuy[1000:] = y_train0[y_train0 == 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "r1RNLw4UezqW"
      },
      "outputs": [],
      "source": [
        "tu, tuy = sklearn.utils.shuffle(tu, tuy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0.0: 500, 1.0: 500, 2.0: 489}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique, counts = np.unique(tuy, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LUPYbonfVmh",
        "outputId": "881d091f-55fa-4d24-bde7-b5fbfc4f2a93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgraciae/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:18:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       500\n",
            "         1.0       1.00      1.00      1.00       499\n",
            "         2.0       1.00      1.00      1.00       490\n",
            "\n",
            "    accuracy                           1.00      1489\n",
            "   macro avg       1.00      1.00      1.00      1489\n",
            "weighted avg       1.00      1.00      1.00      1489\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mod2 = XGBClassifier(**{'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6})\n",
        "mod2.fit(tu, tuy)\n",
        "xgb2 = sklearn.metrics.classification_report(mod2.predict(tu), tuy)\n",
        "print(xgb2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLAtUkMwfvfu",
        "outputId": "65362cd9-69e9-407a-ee69-a1262f682e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1043\n",
            "           1       1.00      1.00      1.00       858\n",
            "           2       1.00      1.00      1.00       200\n",
            "\n",
            "    accuracy                           1.00      2101\n",
            "   macro avg       1.00      1.00      1.00      2101\n",
            "weighted avg       1.00      1.00      1.00      2101\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb3 = sklearn.metrics.classification_report(mod.predict(X_test0), y_test0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_PTXUxhdT1"
      },
      "source": [
        "#  SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jzydAn7Nh2qg"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpi33etshgcb",
        "outputId": "ad71cced-4f23-4309-c584-83d1bad4f63d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 2823, 1: 2823, 2: 2823}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm = SMOTE(random_state = 42, n_jobs = -1)\n",
        "x0, y0 = sm.fit_resample(X_train0, y_train0)\n",
        "unique, counts = np.unique(y0, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8vA5T6ujauu",
        "outputId": "2dacbac0-a138-4254-a33a-cbce418107cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgraciae/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:12:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2822\n",
            "           1       1.00      1.00      1.00      2824\n",
            "           2       1.00      1.00      1.00      2823\n",
            "\n",
            "    accuracy                           1.00      8469\n",
            "   macro avg       1.00      1.00      1.00      8469\n",
            "weighted avg       1.00      1.00      1.00      8469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mod3 = XGBClassifier(**{'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6})\n",
        "mod3.fit(x0, y0)\n",
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(x0), y0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbdN3zWWj5W_",
        "outputId": "a902244d-44f5-4cae-c3b8-5a0cf1194a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92       704\n",
            "           1       0.95      0.92      0.94       574\n",
            "           2       0.67      0.80      0.73       123\n",
            "\n",
            "    accuracy                           0.91      1401\n",
            "   macro avg       0.85      0.88      0.86      1401\n",
            "weighted avg       0.91      0.91      0.91      1401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(X_test0), y_test0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMmuPUgelKnU"
      },
      "source": [
        "# SVMSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GhabdCiMlNSl"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mqNqCRYlVc6",
        "outputId": "5d72287d-2731-4727-ec30-e6e36a9f77ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 2823, 1: 2823, 2: 2823}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm = SVMSMOTE(random_state = 42, n_jobs = -1)\n",
        "x0, y0 = sm.fit_resample(X_train0, y_train0)\n",
        "unique, counts = np.unique(y0, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6nF0H9Ele7C",
        "outputId": "a7290d98-182d-48b2-876b-2c4a6ad0e5f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgraciae/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:13:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2826\n",
            "           1       1.00      1.00      1.00      2823\n",
            "           2       1.00      1.00      1.00      2820\n",
            "\n",
            "    accuracy                           1.00      8469\n",
            "   macro avg       1.00      1.00      1.00      8469\n",
            "weighted avg       1.00      1.00      1.00      8469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mod3 = XGBClassifier(**{'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6})\n",
        "mod3.fit(x0, y0)\n",
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(x0), y0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w99SEKjlkOq",
        "outputId": "c4d2b21e-40f2-401a-a3fc-c084f97f029a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91       710\n",
            "           1       0.95      0.92      0.94       573\n",
            "           2       0.62      0.77      0.69       118\n",
            "\n",
            "    accuracy                           0.90      1401\n",
            "   macro avg       0.83      0.87      0.85      1401\n",
            "weighted avg       0.91      0.90      0.90      1401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(X_test0), y_test0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUK9a1OPmNnE"
      },
      "source": [
        "# KMEANSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_UBBPmuRmQc0"
      },
      "outputs": [],
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et2NA-94mTy2",
        "outputId": "73953978-31cb-49c9-b4b5-e19b3a495522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 2823, 1: 2828, 2: 2823}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm = KMeansSMOTE(random_state = 42, n_jobs = -1)\n",
        "x0, y0 = sm.fit_resample(X_train0, y_train0)\n",
        "unique, counts = np.unique(y0, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt0UicuXmhyJ",
        "outputId": "2ab6ba95-e412-4941-dad7-9c98760ccc57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgraciae/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:13:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2823\n",
            "           1       1.00      1.00      1.00      2828\n",
            "           2       1.00      1.00      1.00      2823\n",
            "\n",
            "    accuracy                           1.00      8474\n",
            "   macro avg       1.00      1.00      1.00      8474\n",
            "weighted avg       1.00      1.00      1.00      8474\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mod3 = XGBClassifier(**{'booster': 'gbtree', 'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 32, 'min_child_weight': 0.5, 'subsample': 0.6})\n",
        "mod3.fit(x0, y0)\n",
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(x0), y0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-utkxQCxmlKs",
        "outputId": "078432c5-9aa3-4ae7-cde1-15f3f766d4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92       720\n",
            "           1       0.95      0.92      0.94       574\n",
            "           2       0.62      0.85      0.72       107\n",
            "\n",
            "    accuracy                           0.91      1401\n",
            "   macro avg       0.84      0.89      0.86      1401\n",
            "weighted avg       0.92      0.91      0.91      1401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb3 = sklearn.metrics.classification_report(mod3.predict(X_test0), y_test0)\n",
        "print(xgb3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3mxxQdSrS9K"
      },
      "source": [
        "# Normalitzant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not achieved better results by normalazing data so I did not input the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best result obtained by cutting data, getting the best f1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "mod2.save_model('../models/XGBClassifier.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To load: \n",
        "# model2 = xgb.XGBRegressor()\n",
        "# model2.load_model('../models/XGBClassifier.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store results as csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = {'Insect' : mod.predict(x_test)}\n",
        "\n",
        "df = pd.DataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('results.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model_train_ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
